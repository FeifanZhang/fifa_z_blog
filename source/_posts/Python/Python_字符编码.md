---
title: Python_字符编码
toc: true
date: 2021-12-11 18:40:42
tags:
- python
- encoding
categories:
- [python, encoding]
---
# 字符编码简介
我们平时在显示器上看到的字符，在计算机中肯定不是以我们看到的样子存储起来的（毕竟计算机只懂得0和1），而是通过字节进行存储，所以将字符转换成字节的过程我们称之为编码（encoding），而将这些字节转换成字符的过程我们称之为解码（decoding），同样的，字节与字符的对应关系则称之为编码集  
# ASCII码
* ASCII 码仅包括了英语单词，阿拉伯数字以及操作字符（`\t`,`\n`,`\r`等控制基础排版的字符），在存储时，将这些字符转换成`0-128`这129个数字（即码位），再将数字转换至二进制（即字节，范围`0000 0000 ~ 0111 1111`）进行储存
* 扩展ASCII码 将字符数量扩展至255(`0000 0000 ~ 1111 1111`)，存入了欧洲国家语言常用字符
# GB 字符编码集
* GB means 国标，是我国发布的汉字编码规范
* 与ASNI的关系：属于ASNI943，也就是说ANSI是兼容GB字符编码集，且兼容的版本为GBK
## GB2312 字符集
* 中国汉字太多，为解决中文编码的难题，采取了分区管理：一共94个区，每个区94个位，每个区为10行10列（行与列的取值范围为0~9）且未被填满
  * 1-9区收录汉字以外的682个字符
  * 10-15区空白
  * 16-55区收录3755个一级汉字（经常使用的汉字），按拼音排序
  * 56-87区收录308个二级汉字（较生僻的汉字），按部首排序
  * 88-94空白未使用
### 字符与码位的对应
* 通过字节的所在`区、行、列`拼接而来
* 举个例子：`y`字符在**03**区的第**8**行第**9**列则码位为**0389**
### 码位与字节的转换
* 码位是由2个16进制的2位数拼接而成，前两位为区字节，对应上文所说的区编号（常见范围`0xB0 ~ 0xF7`）；后两位为位编号，通过字符所在的行和列计算得出（范围`0xA1 ~ 0xFE`）
* 用`侃`字举例子：其码位为5709
  ```mermaid
    flowchart LR
    5709 -->|拆分|57 & 09
    57 -->|转换成16进制| 0x39
    09 -->|转换成16进制| 0x09
    0x39 -->|+0xA0| 0xD9
    0x09 -->|+0xA0| 0xA9
    0xD9 & 0xA9 -->|合并| 0xD90xA9 
  ```
* 可以使用python计算码位
  ```python
  print('侃'.encode('gb2312'))
  # b'\xd9\xa9'
  ```
* 加`0xA0`的原因：使得编码的高、低8位大于127，防止与ASCII码冲突
### GB2312的优缺点
* 好处：有了汉字编码了！
* 坏处：汉字太少，确实不够用
* 所以出现了~~~~~~GBK编码！
## GBK编码
* GBK means 国(G)标(B)扩(K)展
* 在GB2312的基础上，增加了2w个汉字与符号（将之前空白的区进行填充）
* 高8位仍需遵守大于127的限制，而低8位不再`0xA0`该限制
* 也就是说：当计算机识别高8位为大于127时，则判定为中文
### 码位的存储
* still `侃`字举例子：其码位为5709
  ```mermaid
    flowchart LR
    5709 -->|拆分|57 & 09
    57 -->|转换成16进制| 0x39
    09 -->|转换成16进制| 0x09
    0x39 -->|+0xA0| 0xD9
    0xD9 & 0x09 -->|合并| 0xD90x09 
  ```
* 低位不再进行`+0xA0`的操作
## GB 18030
* 在GB2312基础上增加了几千个少数民族字符

# 各国编码的不兼容
* 中国有GB系列字符集，日本有`Shift_JIS`，韩国有`Euc_Kr`，各国都有自己的一套标准，无法统一（有可能一个数字在GB中表示一个中文，用`Shift_JIS`编码打开时可能不存在该数字对应的字符，从而导致乱码）
# Unicode编码
* 一个目的：一套编码表示全世界所有字符，做到真正的编码标准统一
* 范围从 `00000000` ~ `0010FFFF`
## UCS-2字符集
* 可表示$2^{16}$个字符（范围`0x0000 ~ 0xFFFF`）
* 但还是不太够，需要扩充
## UCS-4字符集
* 可表示$2^{32}$个字符 （范围`0x00000 ~ 0xFFFFF`）
* 基本能涵盖所有字符
* 问题就是：所需存储空间过大，所以该标准的推广很慢
* 随着互联网时代来临，各国交流频繁，开始重新考虑Unicode编码，进而推出了UTF-8
## UTF-8编码
* 形成了在Unicode的字符广泛性与储存空间的折中（即编码格式为可变长度）
### 编码规则
* 将`UCS-4`的码位划分成4个区间:
* 表格中的x表示UCS转换成二进制后，把若干二进制的低位填进x中，一个x表示填写1个低位  

    |UCS编码范围（16进制）|对应的UTF-8的编码规则（2进制）|
    |--|--|
    |`0x0000 0000` ~ `0x0000 007F`|`0xxxxxxx`|
    |`0x0000 0080` ~ `0x0000 07FF`|`110xxxxx` `10xxxxxx`|
    |`0x0000 0800` ~ `0x0000 FFFF`|`1110xxxx` `10xxxxxx` `10xxxxxx`|
    |`0x0001 0000` ~ `0x0010 FFFF`|`11110xxx` `10xxxxxx` `10xxxxxx` `10xxxxxx`|
* 王 在UCS-4中的码位为 0000 738B
* 转化为二进制：0000 0000 0000 0000 <font color='Green'>0111</font> <font color='Purple'>0011 10</font><font color='Blue'>00 1011</font>
* 王的编码`0000 738B` 是在`0x0000 07FF` ~ `0x0000 0800`之间，对应表格中第3行的UTF-8编码规则 1110<font color='Green'>xxxx</font> 10<font color='Purple'>xxxxxx</font> 10<font color='Blue'>xxxxxx</font>
* 按颜色将王的二进制数字替换掉UTF-8的编码规则中的x(及由UCS的低位至高位依次替换掉UTF-8编码规则的x)
* UCS-4的码位越小，则在UTF-8中的码位长度越短，通过字节的高位（0，110，10，1110，11110）来判断各个字节之间的关系
### BOM大坑
* **BOM：** byte of mark 是微软为了UTF-16和UTF-32准备的，用于标记字节序，文件开头会带有`U+FEFF`
* **BOM带来的问题：** 带有BOM的UTF-8文件在Windows以外的操作系统打开时可能会有乱码（因为其他操作系统或软件无法处理BOM）
* **解决方法：** 
  * 如果用Windows自带的笔记本去打开UTF-8的文件，就会带有BOM，用NotePad++或其他非微软文件编辑器操作文件则可避免该问题
  * 如下编辑器可很好地处理BOM：VIM，python脚本


